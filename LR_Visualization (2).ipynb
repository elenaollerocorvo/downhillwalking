{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51efc3-bd7c-4b96-80ae-4039afb3cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# allow dataframes to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047af743-71c0-4ac5-ac55-884f13f4c9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ramp_downhill.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83ea17-be8c-432b-a2d5-15d371738b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MuscleJointForces_downhill.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73035777-fffe-4d68-a8d7-ee7d75003b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.json_normalize(data)\n",
    "df_all.columns = df_all.columns.str.replace(r\"^results\\.\", \"\", regex=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38289d-f880-4e50-a53b-5353169ae7e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['angleHip_length'] = df_all['angleHip'].apply(len)\n",
    "print(df_all[['file', 'side', 'angleHip_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50b15a-d07e-4552-b421-fc644f303769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge data\n",
    "df_merged = pd.merge(df_all, df, on=[\"file\", \"side\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9081790-6dc6-4d4b-bbca-78c06c7f7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for plotting\n",
    "label_map = {\n",
    "    \"GRF_ap\": \"GRF Anterior-Posterior (N)\",\n",
    "    \"GRF_ml\": \"GRF Medio-Lateral (N)\",\n",
    "    \"GRF_vert\": \"GRF Vertical (N)\",\n",
    "    \"angleHip\": \"Hip Angle (°)\",\n",
    "    \"angleKnee\": \"Knee Angle (°)\",\n",
    "    \"angleAnkle\": \"Ankle Angle (°)\",\n",
    "    \"momentHip\": \"Hip Moment (Nm)\",\n",
    "    \"momentKnee\": \"Knee Moment (Nm)\",\n",
    "    \"momentAnkle\": \"Ankle Moment (Nm)\",\n",
    "    \"ankleFres\": \"Ankle Joint Reaction Force (N)\",\n",
    "    \"kneeFres\": \"Knee Joint Reaction Force (N)\",\n",
    "    \"hipFres\": \"Hip Joint Reaction Force (N)\",\n",
    "    \"knee_PFc\": \"Patellofemoral Contact Force (N)\",\n",
    "    \"gastrocnemius\": \"Gastrocnemius Force (N)\",\n",
    "    \"soleus\": \"Soleus Force (N)\",\n",
    "    \"tib_ant\": \"Tibialis Anterior Force (N)\",\n",
    "    \"quadriceps\": \"Quadriceps Force (N)\",\n",
    "    \"iliopsoas\": \"Iliopsoas Force (N)\",\n",
    "    \"hamstrings\": \"Hamstrings Force (N)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178690a-32ed-41dd-ab41-edf2035f7478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Definición del diccionario de colores (Esto faltaba en tu ejecución)\n",
    "color_slopes = {\n",
    "    '0': '#3c6d56', \n",
    "    '-6': '#1b5962', \n",
    "    '-12': '#103f60', \n",
    "    '-18': '#011959'\n",
    "}\n",
    "\n",
    "# 2. Definición del label_map\n",
    "label_map = {\n",
    "    \"GRF_ap\": \"GRF Anterior-Posterior (N)\",\n",
    "    \"GRF_ml\": \"GRF Medio-Lateral (N)\",\n",
    "    \"GRF_vert\": \"GRF Vertical (N)\",\n",
    "    \"angleHip\": \"Hip Angle (°)\",\n",
    "    \"angleKnee\": \"Knee Angle (°)\",\n",
    "    \"angleAnkle\": \"Ankle Angle (°)\",\n",
    "    \"momentHip\": \"Hip Moment (Nm)\",\n",
    "    \"momentKnee\": \"Knee Moment (Nm)\",\n",
    "    \"momentAnkle\": \"Ankle Moment (Nm)\",\n",
    "    \"ankleFres\": \"Ankle Joint Reaction Force (N)\",\n",
    "    \"kneeFres\": \"Knee Joint Reaction Force (N)\",\n",
    "    \"hipFres\": \"Hip Joint Reaction Force (N)\",\n",
    "    \"knee_PFc\": \"Patellofemoral Contact Force (N)\",\n",
    "    \"gastrocnemius\": \"Gastrocnemius Force (N)\",\n",
    "    \"soleus\": \"Soleus Force (N)\",\n",
    "    \"tib_ant\": \"Tibialis Anterior Force (N)\",\n",
    "    \"quadriceps\": \"Quadriceps Force (N)\",\n",
    "    \"iliopsoas\": \"Iliopsoas Force (N)\",\n",
    "    \"hamstrings\": \"Hamstrings Force (N)\"\n",
    "}\n",
    "\n",
    "variables_a_tracer = ['angleKnee', 'angleHip', 'angleAnkle', 'GRF_vert', 'knee_PFc', 'kneeFres']\n",
    "\n",
    "# 3. Ordenar pendientes de 0 a -18 (Descendente numéricamente)\n",
    "slopes = sorted(df_merged['slope'].unique(), reverse=True)\n",
    "\n",
    "for var in variables_a_tracer:\n",
    "    # Crear la figura\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 4), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    y_label = label_map.get(var, var)\n",
    "    \n",
    "    for i, slope in enumerate(slopes):\n",
    "        ax = axes[i]\n",
    "        df_sub = df_merged[df_merged['slope'] == slope]\n",
    "        \n",
    "        # Usamos str(int(slope)) para que coincida con las llaves del diccionario '0', '-6', etc.\n",
    "        color = color_slopes.get(str(int(slope)), \"grey\")\n",
    "\n",
    "        for _, row in df_sub.iterrows():\n",
    "            if isinstance(row[var], (list, np.ndarray)):\n",
    "                ax.plot(row[var], color=color, alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f\"Slope: {slope}°\")\n",
    "        ax.set_xlabel('Frames')\n",
    "        if i == 0: # Solo poner el label en el primero para que no se amontone\n",
    "            ax.set_ylabel(y_label)\n",
    "\n",
    "    # Limpiar ejes si hay menos de 4 pendientes\n",
    "    for j in range(len(slopes), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(f\"Analysis of {y_label}\", y=1.05, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85982c-87b5-4ea1-966f-f756ac704973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76594ff0-9ab9-49a6-a2d7-e712ad3caea6",
   "metadata": {},
   "source": [
    "# 0. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de01a8-a33a-4629-a815-b5a6e3471ab4",
   "metadata": {},
   "source": [
    "* Datasets for peak 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae3605-1abf-49cc-98a5-5d40f30e58a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted_rows_p1 = []\n",
    "\n",
    "# Loop through each trial\n",
    "for idx, row in df.iterrows():\n",
    "    # Safety check: make sure the list is not empty\n",
    "    if len(row['GRF_vert']) == 0:\n",
    "        continue\n",
    "        \n",
    "    # taking 30% of the graph (approx to find the first peak)\n",
    "    stance_limit = int(len(row['GRF_vert']) * 0.6)\n",
    "    mid_stance = int(stance_limit / 2)\n",
    "    \n",
    "    # Safety check for very short cycles\n",
    "    if mid_stance <= 0:\n",
    "        continue\n",
    "    \n",
    "    # Find peak indices\n",
    "    idx_peak_grf = np.argmax(row['GRF_vert'][:mid_stance]) \n",
    "    \n",
    "    # Function to extract ALL data at a specific index\n",
    "    def get_all_data_at_index(index, event_name):\n",
    "        data_point = {}\n",
    "        # Manually add Event_Type to ensure it exists\n",
    "        data_point['Event_Type'] = event_name\n",
    "        \n",
    "        for col in df.columns:\n",
    "            val = row[col]\n",
    "            # If it is a list (time-series data) -> take the value at time T\n",
    "            if isinstance(val, (list, np.ndarray)):\n",
    "                try:\n",
    "                    data_point[col] = val[index]\n",
    "                except IndexError:\n",
    "                    data_point[col] = np.nan\n",
    "            # If it is a constant (ID, Weight, Age, etc.) -> keep it as is\n",
    "            else:\n",
    "                data_point[col] = val\n",
    "                \n",
    "        return data_point\n",
    "    \n",
    "\n",
    "    extracted_rows_p1.append(get_all_data_at_index(idx_peak_grf, 'First_Peak_GRF'))\n",
    "\n",
    "# Create the final DataFrame\n",
    "df_peak1 = pd.DataFrame(extracted_rows_p1)\n",
    "\n",
    "# --- COLUMN REORGANIZATION ---\n",
    "# Define priority columns\n",
    "priority_cols = ['id', 'condition', 'Event_Type']\n",
    "\n",
    "# Retrieve all other columns that are NOT in the priority list\n",
    "other_cols = [c for c in df_peak1.columns if c not in priority_cols]\n",
    "\n",
    "# Combine everything: id first, then Event_Type, then the rest\n",
    "final_order = priority_cols + other_cols\n",
    "df_peak1 = df_peak1[final_order]\n",
    "\n",
    "# --- SEPARATION INTO TWO DATAFRAMES ---\n",
    "\n",
    "# 1. DataFrame for 'self-selected'\n",
    "df_self_selected = df_peak1[df_peak1['condition'] == 'self-selected'].copy()\n",
    "\n",
    "# 2. DataFrame for 'constant'\n",
    "df_constant = df_peak1[df_peak1['condition'] == 'constant'].copy()\n",
    "\n",
    "# --- DISPLAY RESULTS ---\n",
    "print(f\"Number of rows (Self Selected): {len(df_self_selected)}\")\n",
    "print(f\"Number of rows (Constant): {len(df_constant)}\")\n",
    "\n",
    "print(\"\\n--- Preview Self Selected ---\")\n",
    "display(df_self_selected.head(20))\n",
    "\n",
    "print(\"\\n--- Preview Constant ---\")\n",
    "display(df_constant.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f65dc-5ce9-49a9-bd95-828162f961dd",
   "metadata": {},
   "source": [
    "* Datasets for peak 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff340d7-e12e-4042-86da-af4d26201b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted_rows_p2 = []\n",
    "\n",
    "# Loop through each trial\n",
    "for idx, row in df.iterrows():\n",
    "    # Safety check: make sure the list is not empty\n",
    "    if len(row['GRF_vert']) == 0:\n",
    "        continue\n",
    "        \n",
    "    stance_limit = int(len(row['GRF_vert']) * 0.6)  # ~60% of the cycle\n",
    "    mid_stance = int(stance_limit / 2)              # ~30% of the cycle\n",
    "    \n",
    "    # Safety check for very short cycles\n",
    "    if mid_stance >= stance_limit:\n",
    "        continue\n",
    "    \n",
    "    # --- MAIN CHANGE HERE ---\n",
    "    # Define the window of interest: from 30% to 60%\n",
    "    slice_grf = row['GRF_vert'][mid_stance:stance_limit]\n",
    "    \n",
    "    # Safety check if the slice is empty\n",
    "    if len(slice_grf) == 0:\n",
    "        continue\n",
    "\n",
    "    # Find peak indices\n",
    "    idx_peak_grf = np.argmax(slice_grf) + mid_stance \n",
    "    \n",
    "    # Function to extract ALL data at a specific index\n",
    "    def get_all_data_at_index(index, event_name):\n",
    "        data_point = {}\n",
    "        # Manually add Event_Type to ensure it exists\n",
    "        data_point['Event_Type'] = event_name\n",
    "        \n",
    "        for col in df.columns:\n",
    "            val = row[col]\n",
    "            # If it is a list (time-series data) -> take the value at time T\n",
    "            if isinstance(val, (list, np.ndarray)):\n",
    "                try:\n",
    "                    data_point[col] = val[index]\n",
    "                except IndexError:\n",
    "                    data_point[col] = np.nan\n",
    "            # If it is a constant (ID, Weight, Age, etc.) -> keep it as is\n",
    "            else:\n",
    "                data_point[col] = val\n",
    "                \n",
    "        return data_point\n",
    "    \n",
    "    # Append data with the new event names\n",
    "    extracted_rows_p2.append(get_all_data_at_index(idx_peak_grf, 'Second_Peak_GRF'))\n",
    "\n",
    "# Create the final DataFrame for the 2nd peak\n",
    "df_peak2 = pd.DataFrame(extracted_rows_p2)\n",
    "\n",
    "# --- COLUMN REORGANIZATION ---\n",
    "# Define priority columns (Added 'condition')\n",
    "priority_cols = ['id', 'condition', 'Event_Type']\n",
    "\n",
    "# Retrieve all other columns that are NOT in the priority list\n",
    "other_cols = [c for c in df_peak2.columns if c not in priority_cols]\n",
    "\n",
    "# Combine everything: id first, then Event_Type, then the rest\n",
    "final_order = priority_cols + other_cols\n",
    "df_peak2 = df_peak2[final_order]\n",
    "\n",
    "# --- SEPARATION INTO TWO DATAFRAMES ---\n",
    "\n",
    "# 1. DataFrame for 'self-selected'\n",
    "df_peak2_self_selected = df_peak2[df_peak2['condition'] == 'self-selected'].copy()\n",
    "\n",
    "# 2. DataFrame for 'constant'\n",
    "df_peak2_constant = df_peak2[df_peak2['condition'] == 'constant'].copy()\n",
    "\n",
    "# --- DISPLAY RESULTS ---\n",
    "print(f\"Number of rows (Self Selected - Peak 2): {len(df_peak2_self_selected)}\")\n",
    "print(f\"Number of rows (Constant - Peak 2): {len(df_peak2_constant)}\")\n",
    "\n",
    "print(\"\\n--- Preview Self Selected (Peak 2) ---\")\n",
    "display(df_peak2_self_selected.head(20))\n",
    "\n",
    "print(\"\\n--- Preview Constant (Peak 2) ---\")\n",
    "display(df_peak2_constant.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d17b5b-ead8-4643-8df6-a939a42f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of every participants\n",
    "tous_les_participants = sorted(df_merged['id'].unique())\n",
    "print(f\"Participants : {tous_les_participants}\")\n",
    "print(f\"Total number of participants : {len(tous_les_participants)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328c6df-550f-4b17-a694-5e130dec25fe",
   "metadata": {},
   "source": [
    "# Visualization for each participant and each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74647a2-02cf-4e8c-86eb-fd3fcfbc9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_subject_analysis(participant_id, df_data):\n",
    "    # 1. Configuración de ID y filtrado\n",
    "    p_id = str(participant_id).strip()\n",
    "    df_sub = df_data[df_data['id'].astype(str).str.strip() == p_id].copy()\n",
    "    \n",
    "    if df_sub.empty:\n",
    "        print(f\"No data found for participant: {p_id}\")\n",
    "        return\n",
    "\n",
    "    variables = ['GRF_vert', 'knee_PFc', 'angleKnee', 'angleAnkle', 'angleHip', 'quadriceps', 'GRF_ap']\n",
    "    slopes = sorted(df_sub['slope'].unique(), reverse=True)\n",
    "    \n",
    "    # --- COLOR EXPLANATION ---\n",
    "    print(f\"\\n{' BIOMECHANICAL ANALYSIS GUIDE ':^80}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"PHASES (Background Shading):\")\n",
    "    print(\"  - Orange Area : Impact Phase (0-30% of stance)\")\n",
    "    print(\"  - Blue Area   : Propulsion Phase (30-60% of stance)\")\n",
    "    print(\"\\nPEAK TIMING MARKERS:\")\n",
    "    print(\"  - RED Circles (●) : Vertical GRF Peak Frame\")\n",
    "    print(\"  - GREEN Cross (X) : Patellofemoral Force Peak Frame\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # 2. Resumen Estadístico Detallado (Frames y Delays)\n",
    "    delay_records = []\n",
    "    for slope in slopes:\n",
    "        df_slope = df_sub[df_sub['slope'] == slope]\n",
    "        for _, row in df_slope.iterrows():\n",
    "            g, p = np.array(row['GRF_vert']), np.array(row['knee_PFc'])\n",
    "            l30, l60 = int(len(g)*0.3), int(len(g)*0.6)\n",
    "            \n",
    "            # P1 Detection\n",
    "            f_g1 = np.argmax(g[:l30])\n",
    "            f_p1 = np.argmax(p[:l30])\n",
    "            \n",
    "            # P2 Detection\n",
    "            f_g2 = np.argmax(g[l30:l60]) + l30\n",
    "            f_p2 = np.argmax(p[l30:l60]) + l30\n",
    "            \n",
    "            delay_records.append({\n",
    "                'Slope': slope,\n",
    "                'P1_GRF_Frame': f_g1,\n",
    "                'P1_PFC_Frame': f_p1,\n",
    "                'P1_Delay': f_p1 - f_g1,\n",
    "                'P2_GRF_Frame': f_g2,\n",
    "                'P2_PFC_Frame': f_p2,\n",
    "                'P2_Delay': f_p2 - f_g2\n",
    "            })\n",
    "    \n",
    "    print(\"\\nDETAILED PEAK TIMING SUMMARY (Average Frames per Slope)\")\n",
    "    # Agrupamos por Slope y calculamos la media de todos los ensayos\n",
    "    summary_df = pd.DataFrame(delay_records).groupby('Slope').mean().round(2)\n",
    "    print(summary_df)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    # 3. Generación de Gráficas por Variable\n",
    "    c_g1, c_g2 = '#FFADAD', '#8B0000' # Reds\n",
    "    c_p1, c_p2 = '#B7E4C7', '#1B4332' # Greens\n",
    "\n",
    "    for var in variables:\n",
    "        fig, axes = plt.subplots(1, len(slopes), figsize=(22, 5), squeeze=False)\n",
    "        var_display_name = label_map.get(var, var)\n",
    "        \n",
    "        for i, slope in enumerate(slopes):\n",
    "            ax = axes[0, i]\n",
    "            df_plot = df_sub[df_sub['slope'] == slope]\n",
    "            \n",
    "            for t_idx, (_, row) in enumerate(df_plot.iterrows()):\n",
    "                y_val = np.array(row[var])\n",
    "                g_ref = np.array(row['GRF_vert'])\n",
    "                p_ref = np.array(row['knee_PFc'])\n",
    "                \n",
    "                l30, l60 = int(len(y_val)*0.3), int(len(y_val)*0.6)\n",
    "                \n",
    "                # Shading\n",
    "                if t_idx == 0:\n",
    "                    ax.axvspan(0, l30, color='orange', alpha=0.1)\n",
    "                    ax.axvspan(l30, l60, color='blue', alpha=0.05)\n",
    "                \n",
    "                ax.plot(y_val, alpha=0.5, linewidth=1.2)\n",
    "                \n",
    "                # Timing detection\n",
    "                ig1, ig2 = np.argmax(g_ref[:l30]), np.argmax(g_ref[l30:l60]) + l30\n",
    "                ip1, ip2 = np.argmax(p_ref[:l30]), np.argmax(p_ref[l30:l60]) + l30\n",
    "\n",
    "                # Markers\n",
    "                ax.scatter([ig1, ig2], [y_val[ig1], y_val[ig2]], c=[c_g1, c_g2], \n",
    "                           s=80, edgecolors='black', label='GRF Peak' if t_idx==0 and i==0 else \"\", zorder=5)\n",
    "                ax.scatter([ip1, ip2], [y_val[ip1], y_val[ip2]], c=[c_p1, c_p2], \n",
    "                           marker='X', s=100, edgecolors='black', label='PFC Peak' if t_idx==0 and i==0 else \"\", zorder=6)\n",
    "\n",
    "            ax.set_title(f\"Slope {slope}°\", fontweight='bold')\n",
    "            if i == 0: ax.set_ylabel(var_display_name)\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        fig.legend(by_label.values(), by_label.keys(), loc='upper center', ncol=6, bbox_to_anchor=(0.5, 1.08))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# EJECUCIÓN\n",
    "plot_subject_analysis(participant_id=11, df_data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f6ced-7d28-48ff-86c1-c28165c365de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(12,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649ff23-552c-49ac-b699-4de020c60793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(13,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989dece-63d3-43ec-a5f7-19b50295f7a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(14,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f3d32-be19-43c6-8f7d-dbd444059239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(15,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d793c3-ef07-4be0-a14a-43e38c1371c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(16,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a55536-513e-4d3c-9449-2fe9a5f4373d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(17,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4159a8-218c-49ae-920f-1ed902e31232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(18,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2b45c-42cf-4d4f-bbb3-30e84d716d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(20,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549dcc37-8205-4178-843e-aa8e33ed78a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(21,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460ffc6-bee8-4f73-982f-1a8dc34fdb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(22,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8320590-fed6-4e08-aa55-1aa654abdccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(23,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cb7aa-3524-42ff-965c-2b7aa463d70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(24,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4df40f-9064-423e-bf1c-23bc83440776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(25,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639849fe-ef36-4f8a-ac64-41818808625f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(26,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c971576-7d6b-4913-95c0-aea4d57dcced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(27,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc27bf-d29e-47cc-b05c-6c560620858f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(29,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380ebf8-2e86-4c08-ba10-1f4dced9ddd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_subject_analysis(30,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5821a3-dd10-461f-9a0b-24c7ebd27522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def plot_population_analysis_with_peaks(df_data, variables=None):\n",
    "    if variables is None:\n",
    "        variables = ['GRF_vert', 'knee_PFc', 'angleKnee', 'quadriceps', 'GRF_ap']\n",
    "    \n",
    "    unique_slopes = sorted(df_data['slope'].unique(), reverse=True)\n",
    "    participants = sorted(df_data['id'].unique())\n",
    "    palette = sns.color_palette(\"tab20\", len(participants))\n",
    "    \n",
    "    # Peak Colors\n",
    "    c_g1, c_g2 = '#FF4D4D', '#8B0000' # Reds\n",
    "    c_p1, c_p2 = '#4DFF4D', '#006400' # Greens\n",
    "\n",
    "    # --- EXPLANATION GUIDE ---\n",
    "    print(f\"\\n{' POPULATION BIOMECHANICAL GUIDE ':^80}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"SHADING: Orange (0-30% Impact) | Blue (30-60% Propulsion)\")\n",
    "    print(\"MARKERS: Circle = GRF Peak Timing | X = PFC Peak Timing\")\n",
    "    print(\"Each line represents the average of one participant.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for var in variables:\n",
    "        fig, axes = plt.subplots(1, len(unique_slopes), figsize=(24, 6), sharey=False, squeeze=False)\n",
    "        var_display_name = label_map.get(var, var)\n",
    "        \n",
    "        for i, slope in enumerate(unique_slopes):\n",
    "            ax = axes[0, i]\n",
    "            \n",
    "            # Sombreado de fondo\n",
    "            ax.axvspan(0, 30, color='orange', alpha=0.1)\n",
    "            ax.axvspan(30, 60, color='blue', alpha=0.05)\n",
    "\n",
    "            for p_idx, p_id in enumerate(participants):\n",
    "                df_sub = df_data[(df_data['id'] == p_id) & (df_data['slope'] == slope)]\n",
    "                if df_sub.empty: continue\n",
    "                \n",
    "                norm_trials = []\n",
    "                peak_positions = {'g1': [], 'g2': [], 'p1': [], 'p2': []}\n",
    "\n",
    "                for _, row in df_sub.iterrows():\n",
    "                    y = np.array(row[var])\n",
    "                    g_ref = np.array(row['GRF_vert'])\n",
    "                    p_ref = np.array(row['knee_PFc'])\n",
    "                    \n",
    "                    # 1. Detect peaks in original frames\n",
    "                    l30, l60 = int(len(g_ref)*0.3), int(len(g_ref)*0.6)\n",
    "                    ig1, ig2 = np.argmax(g_ref[:l30]), np.argmax(g_ref[l30:l60]) + l30\n",
    "                    ip1, ip2 = np.argmax(p_ref[:l30]), np.argmax(p_ref[l30:l60]) + l30\n",
    "                    \n",
    "                    # 2. Convert peak frames to percentage (%)\n",
    "                    peak_positions['g1'].append((ig1 / len(g_ref)) * 100)\n",
    "                    peak_positions['g2'].append((ig2 / len(g_ref)) * 100)\n",
    "                    peak_positions['p1'].append((ip1 / len(p_ref)) * 100)\n",
    "                    peak_positions['p2'].append((ip2 / len(p_ref)) * 100)\n",
    "\n",
    "                    # 3. Normalize variable data\n",
    "                    x_old = np.linspace(0, 100, len(y))\n",
    "                    x_new = np.linspace(0, 100, 101)\n",
    "                    norm_trials.append(interp1d(x_old, y, kind='linear')(x_new))\n",
    "                \n",
    "                # Mean trajectory and mean peak positions\n",
    "                mean_y = np.mean(norm_trials, axis=0)\n",
    "                m_g1, m_g2 = np.mean(peak_positions['g1']), np.mean(peak_positions['g2'])\n",
    "                m_p1, m_p2 = np.mean(peak_positions['p1']), np.mean(peak_positions['p2'])\n",
    "\n",
    "                # --- PLOT LINE ---\n",
    "                line_color = palette[p_idx]\n",
    "                ax.plot(x_new, mean_y, color=line_color, alpha=0.6, linewidth=1.5, label=f\"Subj {p_id}\" if i==0 else \"\")\n",
    "\n",
    "                # --- PLOT PEAKS (On the mean line at the mean % frame) ---\n",
    "                # GRF Peaks (Circles)\n",
    "                ax.scatter([m_g1, m_g2], [mean_y[int(m_g1)], mean_y[int(m_g2)]], \n",
    "                           color=[c_g1, c_g2], s=50, edgecolors='white', zorder=5)\n",
    "                # PFC Peaks (X)\n",
    "                ax.scatter([m_p1, m_p2], [mean_y[int(m_p1)], mean_y[int(m_p2)]], \n",
    "                           color=[c_p1, c_p2], marker='X', s=70, edgecolors='black', zorder=6)\n",
    "\n",
    "            ax.set_title(f\"Slope {slope}°\", fontweight='bold')\n",
    "            ax.set_xlabel(\"% of Stance\")\n",
    "            if i == 0: ax.set_ylabel(var_display_name)\n",
    "            ax.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "        # Legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        fig.legend(by_label.values(), by_label.keys(), loc='center right', bbox_to_anchor=(1.0, 0.5), title=\"Participants\")\n",
    "        \n",
    "        plt.suptitle(f\"Population Comparison: {var_display_name}\\nRed=GRF Timing | Green=PFC Timing\", y=1.05, fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout(rect=[0, 0.03, 0.93, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "# EJECUCIÓN\n",
    "plot_population_analysis_with_peaks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055c824-a7a5-4dcb-a007-c7c6b66ac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_super_summary_v4(df_data):\n",
    "    all_records = []\n",
    "    # Obtenemos IDs y Slopes únicos\n",
    "    participants = sorted(df_data['id'].unique())\n",
    "    \n",
    "    for p_id in participants:\n",
    "        df_sub = df_data[df_data['id'] == p_id]\n",
    "        slopes = sorted(df_sub['slope'].unique(), reverse=True)\n",
    "        \n",
    "        for slope in slopes:\n",
    "            df_slope = df_sub[df_sub['slope'] == slope]\n",
    "            \n",
    "            # Listas para almacenar valores de cada ensayo\n",
    "            temp_p1_g, temp_p1_p = [], []\n",
    "            temp_p2_g, temp_p2_p = [], []\n",
    "            \n",
    "            for _, row in df_slope.iterrows():\n",
    "                g = np.array(row['GRF_vert'])\n",
    "                p = np.array(row['knee_PFc'])\n",
    "                \n",
    "                # Definición de ventanas (0-30% y 30-60%)\n",
    "                l30, l60 = int(len(g)*0.3), int(len(g)*0.6)\n",
    "                \n",
    "                # Detección de frames\n",
    "                f_g1, f_p1 = np.argmax(g[:l30]), np.argmax(p[:l30])\n",
    "                f_g2 = np.argmax(g[l30:l60]) + l30\n",
    "                f_p2 = np.argmax(p[l30:l60]) + l30\n",
    "                \n",
    "                temp_p1_g.append(f_g1); temp_p1_p.append(f_p1)\n",
    "                temp_p2_g.append(f_g2); temp_p2_p.append(f_p2)\n",
    "            \n",
    "            # Calcular promedios para este participante en esta pendiente\n",
    "            m_g1, m_p1 = np.mean(temp_p1_g), np.mean(temp_p1_p)\n",
    "            m_g2, m_p2 = np.mean(temp_p2_g), np.mean(temp_p2_p)\n",
    "            d1, d2 = m_p1 - m_g1, m_p2 - m_g2\n",
    "            \n",
    "            all_records.append({\n",
    "                'ID': p_id,\n",
    "                'Slope': slope,\n",
    "                'P1_GRF_Fr': round(m_g1, 2),\n",
    "                'P1_PFC_Fr': round(m_p1, 2),\n",
    "                'P1_Delay': d1,\n",
    "                'P2_GRF_Fr': round(m_g2, 2),\n",
    "                'P2_PFC_Fr': round(m_p2, 2),\n",
    "                'P2_Delay': d2\n",
    "            })\n",
    "\n",
    "    # Crear el DataFrame resumen\n",
    "    super_df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Función de marcado con asterisco (Criterio: > 4 o < 0)\n",
    "    def apply_asterisk(val):\n",
    "        if val > 4 or val < 0:\n",
    "            return f\"{val:.2f}*\"\n",
    "        return f\"{val:.2f}\"\n",
    "\n",
    "    # Aplicar formato a las columnas de Delay\n",
    "    super_df['P1_Delay'] = super_df['P1_Delay'].apply(apply_asterisk)\n",
    "    super_df['P2_Delay'] = super_df['P2_Delay'].apply(apply_asterisk)\n",
    "    \n",
    "    return super_df\n",
    "\n",
    "# EJECUCIÓN\n",
    "final_table = generate_super_summary_v4(df)\n",
    "\n",
    "# Visualización\n",
    "print(f\"\\n{' BIOMECHANICAL PEAK DELAY SUMMARY ':=^95}\")\n",
    "print(f\"{'Criterio *: Delay > 4 frames o Negativo':^95}\")\n",
    "print(\"-\" * 95)\n",
    "print(final_table.to_string(index=False))\n",
    "print(\"-\" * 95)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbeb0bd-0b02-4944-a1bd-5de8ffbfb953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
